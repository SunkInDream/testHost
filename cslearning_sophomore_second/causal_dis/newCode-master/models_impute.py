import os
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
import multiprocessing as mp 
from models_TCDF import *
import torch.nn.functional as F
from pygrinder import (
    mcar,
    mar_logistic,
    mnar_x,
    mnar_t,
    mnar_nonuniform,
    rdo,
    seq_missing,
    block_missing,
    calc_missing_rate
)
from sklearn.cluster import KMeans
from models_CAUSAL import *
from models_TCDF import *
from baseline import *
from models_downstream import *
def impute(original, causal_matrix, model_params, epochs=100, lr=0.01, gpu_id=None):
    if gpu_id is not None and torch.cuda.is_available():
        device = torch.device(f'cuda:{gpu_id}')
    else:
        device = torch.device('cpu')
    
    # é¢„è®¡ç®—æ‰€æœ‰å¼ é‡
    mask = (~np.isnan(original)).astype(int)
    initial_filled = initial_process(original)
    sequence_len, total_features = initial_filled.shape
    final_filled = initial_filled.copy()
    
    # æ‰¹å¤„ç†å‡†å¤‡æ•°æ®
    all_inputs = []
    all_targets = []
    all_masks = []
    all_inds = []
    
    for target in range(total_features):
        inds = list(np.where(causal_matrix[:, target] == 1)[0])
        if target not in inds:
            inds.append(target)
        else:
            inds.remove(target)
            inds.append(target)
        inds = inds[:3] + [target]
        
        inp = torch.tensor(initial_filled[:, inds].T[np.newaxis, ...], dtype=torch.float32).to(device)
        y_np = torch.tensor(initial_filled[:, target][np.newaxis, :, None], dtype=torch.float32).to(device)
        m_np = torch.tensor((mask[:, target] == 1)[np.newaxis, :, None], dtype=torch.float32).to(device)
        
        all_inputs.append(inp)
        all_targets.append(y_np)
        all_masks.append(m_np)
        all_inds.append(inds)
    
    # å¹¶è¡Œè®­ç»ƒå¤šä¸ªç‰¹å¾
    for target in range(total_features):
        x, y, m, inds = all_inputs[target], all_targets[target], all_masks[target], all_inds[target]
        
        model = ADDSTCN(target, input_size=len(inds), cuda=(device != torch.device('cpu')), **model_params).to(device)
        
        # ä¼˜åŒ–å™¨è®¾ç½®
        optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)  # AdamWæ›´å¿«
        scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=lr*5, total_steps=epochs)  # æ›´æ¿€è¿›çš„è°ƒåº¦
        
        # ç¼–è¯‘æ¨¡å‹åŠ é€Ÿï¼ˆPyTorch 2.0+ï¼‰
        if hasattr(torch, 'compile'):
            try:
                model = torch.compile(model)
            except:
                pass  # å¦‚æœç¼–è¯‘å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸæ¨¡å‹
        
        best_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(epochs):
            model.train()
            pred = model(x)
            loss = F.mse_loss(pred * m, y * m) + 0.001 * sum(p.abs().sum() for p in model.parameters())
            
            optim.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optim.step()
            scheduler.step()
            
            # æ—©åœç­–ç•¥
            if loss.item() < best_loss:
                best_loss = loss.item()
                patience_counter = 0
            else:
                patience_counter += 1
                if patience_counter > 10:  # æ—©åœ
                    break
        
        # é¢„æµ‹
        model.eval()
        with torch.no_grad():
            out = model(x).squeeze().cpu().numpy()
            to_fill = np.where(mask[:, target] == 0)
            final_filled[to_fill, target] = out[to_fill]
    
    return final_filled

def impute_single_file(args):
    """å•æ–‡ä»¶å¡«è¡¥å‡½æ•°ï¼Œç”¨äºè¿›ç¨‹æ± """
    file_path, causal_matrix, model_params, epochs, lr, gpu_id = args
    
    # è®¾ç½®GPU
    if gpu_id != 'cpu' and torch.cuda.is_available():
        torch.cuda.set_device(gpu_id)
        device = torch.device(f'cuda:{gpu_id}')
    else:
        device = torch.device('cpu')
    
    try:
        # è¯»å–æ•°æ®
        data = pd.read_csv(file_path).values.astype(np.float32)
        filename = os.path.basename(file_path)
        
        # è°ƒç”¨ä¼˜åŒ–åçš„imputeå‡½æ•°
        result = impute(data, causal_matrix, model_params, epochs=epochs, lr=lr, gpu_id=gpu_id)
        
        return filename, result
    except Exception as e:
        return os.path.basename(file_path), None

def parallel_impute(causal_matrix, input_dir, model_params, epochs=100, lr=0.01, max_workers=None):
    """ä½¿ç”¨è¿›ç¨‹æ± çš„å¹¶è¡Œå¡«è¡¥"""
    # è·å–æ–‡ä»¶åˆ—è¡¨
    file_list = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(".csv")]
    
    # ç¡®å®šå·¥ä½œè¿›ç¨‹æ•°å’ŒGPUåˆ†é…
    num_gpus = torch.cuda.device_count()
    if num_gpus == 0:
        max_workers = max_workers or os.cpu_count()
        gpu_ids = ['cpu'] * len(file_list)
    else:
        # æ¯ä¸ªGPUè¿è¡Œ2ä¸ªè¿›ç¨‹ä»¥æé«˜åˆ©ç”¨ç‡
        max_workers = max_workers or (num_gpus * 2)
        gpu_ids = [i % num_gpus for i in range(len(file_list))]
    
    print(f"ä½¿ç”¨ {max_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œå¤„ç† {len(file_list)} ä¸ªæ–‡ä»¶")
    
    # å‡†å¤‡å‚æ•°åˆ—è¡¨
    args_list = [(file_path, causal_matrix, model_params, epochs, lr, gpu_id) 
                 for file_path, gpu_id in zip(file_list, gpu_ids)]
    
    # å¹¶è¡Œæ‰§è¡Œ
    with Pool(processes=max_workers) as pool:
        results = list(tqdm(
            pool.imap(impute_single_file, args_list),
            total=len(file_list),
            desc="æ‰¹é‡å¡«è¡¥ä¸­",
            ncols=80
        ))
    
    # ä¿å­˜ç»“æœ
    os.makedirs("./data_imputed/my_model", exist_ok=True)
    successful_results = []
    
    for filename, result in results:
        if result is not None:
            successful_results.append(result)
            pd.DataFrame(result).to_csv(f"./data_imputed/my_model/{filename}", index=False)
        else:
            print(f"[é”™è¯¯] {filename} å¡«è¡¥å¤±è´¥")
    
    print(f"æˆåŠŸå¡«è¡¥ {len(successful_results)}/{len(file_list)} ä¸ªæ–‡ä»¶")
    return successful_results

def agregate(initial_filled, n_cluster):
    # Step 1: æ¯ä¸ªæ ·æœ¬æŒ‰åˆ—å–å‡å€¼ï¼Œæ„é€ èšç±»è¾“å…¥
    data = np.array([np.nanmean(x, axis=0) for x in initial_filled])

    # Step 2: KMeans èšç±»
    km = KMeans(n_clusters=n_cluster, n_init=10, random_state=0)
    labels = km.fit_predict(data)

    # Step 3: é€ç±»æ‰¾ä»£è¡¨æ ·æœ¬ï¼Œå¸¦è¿›åº¦æ¡
    idx_arr = []
    for k in tqdm(range(n_cluster), desc="é€‰æ‹©æ¯ç°‡ä»£è¡¨æ ·æœ¬"):
        idxs = np.where(labels == k)[0]
        if len(idxs) == 0:
            continue
        cluster_data = data[idxs]
        dists = np.linalg.norm(cluster_data - km.cluster_centers_[k], axis=1)
        best_idx = idxs[np.argmin(dists)]
        idx_arr.append(int(best_idx))

    return idx_arr
# def causal_worker(task_queue, result_queue, initial_matrix_arr, params, gpu_id):
#     """
#     æ¯ä¸ªè¿›ç¨‹è¿è¡Œçš„ workerï¼Œç»‘å®šæŒ‡å®š GPUï¼Œå¤„ç† task_queue ä¸­çš„ä»»åŠ¡
#     """
#     os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
#     torch.cuda.set_device(0)  # æ¯ä¸ªå­è¿›ç¨‹çœ‹çš„æ˜¯ CUDA_VISIBLE_DEVICES ä¸‹çš„ cuda:0

#     while True:
#         item = task_queue.get()
#         if item is None:
#             break
#         task_id, i = item
#         try:
#             matrix = compute_causal_matrix(initial_matrix_arr[i], params=params, gpu_id=0)
#             result_queue.put((task_id, matrix))
#         except Exception as e:
#             print(f"[GPU {gpu_id}] ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
#             result_queue.put((task_id, None))
def causal_discovery(original_matrix_arr, n_cluster=5, isStandard=False, standard_cg=None,
                     params={
                         'layers': 6,
                         'kernel_size': 6,
                         'dilation_c': 4,
                         'optimizername': 'Adam',
                         'lr': 0.02,
                         'epochs': 100,
                         'significance': 1.2,
                     }):

    if isStandard:
        if standard_cg is None:
            raise ValueError("standard_cg must be provided when isStandard is True")
        else:
            return standard_cg

    # Step 1: é¢„å¤„ç†æ•°æ®
    initial_matrix_arr = original_matrix_arr.copy()
    for i in tqdm(range(len(initial_matrix_arr)), desc="é¢„å¤„ç†æ ·æœ¬"):
        initial_matrix_arr[i] = initial_process(initial_matrix_arr[i])

    # Step 2: èšç±»å¹¶è·å–æ¯ç»„ç´¢å¼•
    idx_arr = agregate(initial_matrix_arr, n_cluster)

    # Step 3: å¤š GPU å¹¶è¡Œè®¡ç®— causal_matrix
    # num_gpus = torch.cuda.device_count()
    # task_queue = mp.Queue()
    # result_queue = mp.Queue()

    # for task_id, i in enumerate(idx_arr):
    #     task_queue.put((task_id, i))
    # for _ in range(num_gpus):
    #     task_queue.put(None)

    # workers = []
    # for gpu_id in range(num_gpus):
    #     p = mp.Process(target=causal_worker, args=(task_queue, result_queue, initial_matrix_arr, params, gpu_id))
    #     p.start()
    #     workers.append(p)

    # results = [None] * len(idx_arr)

    # # âœ… ç”¨ tqdm åŒ…è£¹ result_queue.get() è·å–è¿›åº¦æ¡
    # for _ in tqdm(range(len(idx_arr)), desc="å› æœå‘ç°ä¸­"):
    #     task_id, matrix = result_queue.get()
    #     results[task_id] = matrix

    # for p in workers:
    #     p.join()
    data_list = []
    for idx in idx_arr:  # idx_arr æ˜¯ä»£è¡¨æ ·æœ¬çš„ç´¢å¼•åˆ—è¡¨
        data_list.append(initial_matrix_arr[idx]) 
    params_list = [params] * len(data_list)  
    results = parallel_compute_causal_matrices(data_list, params_list)
    # Step 4: åˆå¹¶ç»“æœ
    cg_total = None
    for matrix in results:
        if matrix is None:
            continue
        if cg_total is None:
            cg_total = matrix.copy()
        else:
            cg_total += matrix

    if cg_total is None:
        raise RuntimeError("æ‰€æœ‰ä»»åŠ¡éƒ½å¤±è´¥ï¼Œæœªèƒ½å¾—åˆ°æœ‰æ•ˆçš„å› æœçŸ©é˜µ")

    # Step 5: é€‰ top3 ä½œä¸º final causal graph
    np.fill_diagonal(cg_total, 0)
    new_matrix = np.zeros_like(cg_total)
    for col in range(cg_total.shape[1]):
        temp_col = cg_total[:, col].copy()
        if np.count_nonzero(temp_col) < 3:
            new_matrix[:, col] = 1
        else:
            top3 = np.argsort(temp_col)[-3:]
            new_matrix[top3, col] = 1

    return new_matrix
def mse_evaluate_single(args):
    """å•ä¸ªMSEè¯„ä¼°ä»»åŠ¡å‡½æ•°ï¼Œç”¨äºè¿›ç¨‹æ± """
    task_data, causal_matrix, gpu_id = args
    
    # åœ¨ä»»ä½•TensorFlowæ“ä½œä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡
    import os
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id) if gpu_id != 'cpu' else ""
    os.environ["TF_FORCE_GPU_ALLOW_GROWTH"] = "true"
    
    # ç°åœ¨å¯¼å…¥TensorFlow
    import tensorflow as tf
    
    # é…ç½®TensorFlow
    if gpu_id != 'cpu':
        # é…ç½®GPUå†…å­˜å¢é•¿
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            try:
                # åœ¨å­è¿›ç¨‹ä¸­ï¼Œåªèƒ½çœ‹åˆ°ä¸€ä¸ªGPUï¼ˆç”±CUDA_VISIBLE_DEVICESè®¾ç½®ï¼‰
                tf.config.experimental.set_memory_growth(gpus[0], True)
                print(f"[Worker {gpu_id}] TensorFlowé…ç½®GPUæˆåŠŸ")
            except RuntimeError as e:
                print(f"[Worker {gpu_id}] TensorFlow GPUé…ç½®å¤±è´¥: {e}")
    
    # è®¾ç½®PyTorch GPU
    if gpu_id != 'cpu' and torch.cuda.is_available():
        torch.cuda.set_device(0)  # åœ¨å­è¿›ç¨‹ä¸­æ€»æ˜¯0ï¼ˆç”±ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
        device = torch.device('cuda:0')
        print(f"[Worker {gpu_id}] PyTorchä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device('cpu')
        print(f"[Worker {gpu_id}] ä½¿ç”¨CPU")
    
    try:
        # æ•°æ®è§£åŒ…é€»è¾‘
        if isinstance(task_data, tuple):
            if len(task_data) == 2:
                idx, data = task_data
                if isinstance(data, tuple) and len(data) == 2:
                    filename, matrix = data
                    print(f"[Worker {gpu_id}] å¤„ç†æ–‡ä»¶ {filename}")
                else:
                    matrix = data
                    print(f"[Worker {gpu_id}] å¤„ç†ç´¢å¼• {idx}")
            else:
                print(f"[Worker {gpu_id}] æ„å¤–çš„æ•°æ®æ ¼å¼: {type(task_data)}, é•¿åº¦: {len(task_data)}")
                idx = 0
                matrix = task_data[-1]
        else:
            idx = 0
            matrix = task_data
            print(f"[Worker {gpu_id}] ç›´æ¥å¤„ç†çŸ©é˜µæ•°æ®")
        
        # éªŒè¯è¾“å…¥
        if not isinstance(matrix, np.ndarray):
            raise TypeError(f"æœŸæœ›numpyæ•°ç»„ï¼Œå¾—åˆ°{type(matrix)}")
        if matrix.ndim != 2:
            raise ValueError(f"æœŸæœ›äºŒç»´çŸ©é˜µï¼Œå¾—åˆ°{matrix.ndim}ç»´")
        
        # æ‰§è¡ŒMSEè¯„ä¼° - ä¼ é€’å®é™…çš„GPUè®¾å¤‡ID
        actual_gpu_id = 0 if gpu_id != 'cpu' else None
        result = mse_evaluate_safe(matrix, causal_matrix, device=device, tf_gpu_id=actual_gpu_id)
        
        return idx, result
        
    except Exception as e:
        import traceback
        print(f"[Worker {gpu_id}] è¯„ä¼°ä»»åŠ¡å¤±è´¥: {e}")
        print(traceback.format_exc())
        return 0, None

def mse_evaluate_safe(mx, causal_matrix, device=None, tf_gpu_id=None):
    """å®‰å…¨çš„MSEè¯„ä¼°å‡½æ•°ï¼Œé¿å…TensorFlowè®¾å¤‡å†²çª"""
    if device is None:
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    
    gpu_id = tf_gpu_id if tf_gpu_id is not None else 0
    
    ground_truth = mx.copy()
    X_block_3d = block_missing(mx[np.newaxis, ...], factor=0.1, block_width=3, block_len=3)
    X_block = X_block_3d[0]

    def mse_pytorch(a, b):
        """ä½¿ç”¨PyTorchè®¡ç®—MSE"""
        try:
            if isinstance(a, np.ndarray):
                a_tensor = torch.from_numpy(a).float()
            else:
                a_tensor = a.float()
                
            if isinstance(b, np.ndarray):
                b_tensor = torch.from_numpy(b).float()
            else:
                b_tensor = b.float()
            
            # åˆ†æ‰¹å¤„ç†é¿å…å†…å­˜é—®é¢˜
            if a_tensor.numel() > 500000:
                batch_size = 100000
                total_loss = 0
                total_elements = 0
                
                a_flat = a_tensor.view(-1)
                b_flat = b_tensor.view(-1)
                
                for i in range(0, a_flat.numel(), batch_size):
                    end_idx = min(i + batch_size, a_flat.numel())
                    a_batch = a_flat[i:end_idx].to(device)
                    b_batch = b_flat[i:end_idx].to(device)
                    
                    batch_loss = F.mse_loss(a_batch, b_batch, reduction='sum')
                    total_loss += batch_loss.cpu().item()
                    total_elements += a_batch.numel()
                    
                    del a_batch, b_batch, batch_loss
                    if device.type == 'cuda':
                        torch.cuda.empty_cache()
                
                return total_loss / total_elements
            else:
                a_tensor = a_tensor.to(device)
                b_tensor = b_tensor.to(device)
                result = F.mse_loss(a_tensor, b_tensor).cpu().item()
                
                del a_tensor, b_tensor
                if device.type == 'cuda':
                    torch.cuda.empty_cache()
                
                return result
                
        except Exception as e:
            print(f"MSEè®¡ç®—å¤±è´¥: {e}")
            return float('inf')

    results = {}
    
    # 1. æˆ‘ä»¬çš„æ–¹æ³•
    try:
        print(f"[GPU {gpu_id}] è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•...")
        imputed = impute(
            X_block, causal_matrix,
            model_params={'num_levels': 6, 'kernel_size': 6, 'dilation_c': 4},
            epochs=50, lr=0.01, gpu_id=gpu_id
        )
        results['my_model'] = mse_pytorch(imputed, ground_truth)
        print(f"âœ… æˆ‘ä»¬çš„æ–¹æ³• MSE: {results['my_model']:.6f}")
        del imputed
    except Exception as e:
        print(f"âŒ æˆ‘ä»¬çš„æ–¹æ³•å¤±è´¥: {e}")
        results['my_model'] = float('inf')
    
    # 2. ç®€å•åŸºçº¿æ–¹æ³•
    simple_methods = [
        ('zero_impu', zero_impu),
        ('mean_impu', mean_impu), 
        ('median_impu', median_impu),
        ('mode_impu', mode_impu),
        ('random_impu', random_impu),
        ('knn_impu', knn_impu),
        ('ffill_impu', ffill_impu),
        ('bfill_impu', bfill_impu),
    ]
    
    for method_name, method_func in simple_methods:
        try:
            result = method_func(X_block)
            results[method_name] = mse_pytorch(result, ground_truth)
            del result
        except Exception as e:
            print(f"âŒ {method_name} å¤±è´¥: {e}")
            results[method_name] = float('inf')
    
    # 3. TensorFlowæ–¹æ³• - ä½¿ç”¨å…¨å±€é…ç½®
    tf_methods = [
        ('miracle_impu', miracle_impu),
        ('saits_impu', saits_impu),
        ('timemixerpp_impu', timemixerpp_impu),
        ('tefn_impu', tefn_impu),
    ]
    
    import tensorflow as tf
    
    # åˆ›å»ºå•ä¸€çš„TensorFlowé…ç½®
    config = tf.compat.v1.ConfigProto()
    config.gpu_options.allow_growth = True
    if device.type == 'cuda':
        config.gpu_options.visible_device_list = "0"  # å­è¿›ç¨‹ä¸­æ€»æ˜¯ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è§GPU
    
    for method_name, method_func in tf_methods:
        try:
            print(f"ğŸ”„ [GPU {gpu_id}] è¯„ä¼° {method_name}...")
            
            # ä½¿ç”¨ç»Ÿä¸€çš„ä¼šè¯é…ç½®
            with tf.compat.v1.Session(config=config) as sess:
                result = method_func(X_block)
                results[method_name] = mse_pytorch(result, ground_truth)
                print(f"âœ… {method_name} MSE: {results[method_name]:.6f}")
                del result
                
        except Exception as e:
            print(f"âŒ {method_name} å¤±è´¥: {e}")
            results[method_name] = float('inf')
        finally:
            # æ¸…ç†èµ„æº
            if device.type == 'cuda':
                torch.cuda.empty_cache()
    
    return results

def parallel_mse_evaluate(res_list, causal_matrix, max_workers=None):
    """ä½¿ç”¨è¿›ç¨‹æ± çš„å¹¶è¡ŒMSEè¯„ä¼°ï¼Œä¸parallel_imputeç›¸åŒçš„æ¨¡å¼"""
    
    # ç¡®å®šå·¥ä½œè¿›ç¨‹æ•°å’ŒGPUåˆ†é…
    num_gpus = torch.cuda.device_count()
    if num_gpus == 0:
        max_workers = max_workers or os.cpu_count()
        gpu_ids = ['cpu'] * len(res_list)
        print(f"ä½¿ç”¨ {max_workers} ä¸ªCPUè¿›ç¨‹å¤„ç† {len(res_list)} ä¸ªMSEè¯„ä¼°ä»»åŠ¡")
    else:
        # æ¯ä¸ªGPUè¿è¡Œ2ä¸ªè¿›ç¨‹ä»¥æé«˜åˆ©ç”¨ç‡
        max_workers = max_workers or (num_gpus * 2)
        gpu_ids = [i % num_gpus for i in range(len(res_list))]
        print(f"ä½¿ç”¨ {max_workers} ä¸ªè¿›ç¨‹ï¼Œ{num_gpus} ä¸ªGPUå¹¶è¡Œå¤„ç† {len(res_list)} ä¸ªMSEè¯„ä¼°ä»»åŠ¡")
    
    # å‡†å¤‡å‚æ•°åˆ—è¡¨ - ç®€åŒ–æ•°æ®ç»“æ„
    args_list = []
    for i, matrix in enumerate(res_list):
        # ç®€åŒ–ï¼šç›´æ¥ä¼ é€’ (ç´¢å¼•, çŸ©é˜µ) çš„æ ¼å¼
        task_data = (i, matrix)
        args_list.append((task_data, causal_matrix, gpu_ids[i]))
    
    print(f"å‡†å¤‡å¤„ç† {len(args_list)} ä¸ªMSEè¯„ä¼°ä»»åŠ¡")
    
    # å¹¶è¡Œæ‰§è¡Œ
    with Pool(processes=max_workers) as pool:
        results_raw = list(tqdm(
            pool.imap(mse_evaluate_single, args_list),
            total=len(res_list),
            desc="MSEè¯„ä¼°ä¸­",
            ncols=80
        ))
    
    # æŒ‰ç´¢å¼•æ’åºç»“æœ
    results = [None] * len(res_list)
    for idx, result in results_raw:
        if idx < len(results):
            results[idx] = result
    
    # å¤„ç†ç»“æœç»Ÿè®¡ - ä¸“é—¨è°ƒè¯•TimeMixerPP
    valid_mse_dicts = [d for d in results if d is not None and isinstance(d, dict)]
    
    if not valid_mse_dicts:
        print("é”™è¯¯: æ‰€æœ‰MSEè¯„ä¼°ä»»åŠ¡å‡å¤±è´¥!")
        return None
    else:
        print(f"æˆåŠŸå®Œæˆ {len(valid_mse_dicts)}/{len(results)} ä¸ªMSEè¯„ä¼°")
        
        # ç‰¹åˆ«è°ƒè¯•TimeMixerPPçš„æ‰€æœ‰ç»“æœ
        print("\nğŸ” TimeMixerPP è¯¦ç»†ç»“æœåˆ†æ:")
        timemixer_values = []
        for i, d in enumerate(valid_mse_dicts):
            if d is not None and 'timemixerpp_impu' in d:
                value = d['timemixerpp_impu']
                timemixer_values.append((i, value))
                if np.isinf(value):
                    print(f"  ä»»åŠ¡ {i}: {value} âš ï¸ INF")
                elif value > 1e6:
                    print(f"  ä»»åŠ¡ {i}: {value:.2e} âš ï¸ æå¤§å€¼")
                else:
                    print(f"  ä»»åŠ¡ {i}: {value:.6f} âœ…")
        
        print(f"\nTimeMixerPP ç»Ÿè®¡:")
        values_only = [v for _, v in timemixer_values]
        finite_values = [v for v in values_only if not np.isinf(v) and not np.isnan(v)]
        inf_count = sum(1 for v in values_only if np.isinf(v))
        
        print(f"  - æ€»ä»»åŠ¡æ•°: {len(values_only)}")
        print(f"  - æœ‰é™å€¼æ•°é‡: {len(finite_values)}")
        print(f"  - inf å€¼æ•°é‡: {inf_count}")
        
        if finite_values:
            print(f"  - æœ‰é™å€¼èŒƒå›´: [{min(finite_values):.6f}, {max(finite_values):.6f}]")
            print(f"  - æœ‰é™å€¼å¹³å‡: {sum(finite_values)/len(finite_values):.6f}")
        
        # è®¡ç®—æ‰€æœ‰æ–¹æ³•çš„å¹³å‡MSE
        avg_mse = {}
        for method in tqdm(valid_mse_dicts[0].keys(), desc="è®¡ç®—å¹³å‡ MSE"):
            vals = []
            inf_count = 0
            large_count = 0  # æå¤§å€¼è®¡æ•°
            
            for d in valid_mse_dicts:
                if d is not None and method in d:
                    value = d[method]
                    if isinstance(value, (int, float)) and not isinstance(value, bool):
                        if np.isinf(value):
                            inf_count += 1
                        elif value > 1e10:  # æå¤§å€¼é˜ˆå€¼
                            large_count += 1
                            print(f"âš ï¸ {method} å‘ç°æå¤§å€¼: {value:.2e}")
                        elif not np.isnan(value):
                            vals.append(float(value))
            
            # ç‰¹åˆ«å¤„ç†TimeMixerPP
            if method == 'timemixerpp_impu':
                print(f"\n{method} æœ€ç»ˆç»Ÿè®¡:")
                print(f"  - æ­£å¸¸å€¼: {len(vals)} ä¸ª")
                print(f"  - infå€¼: {inf_count} ä¸ª")
                print(f"  - æå¤§å€¼: {large_count} ä¸ª")
                
                if len(vals) > 0:
                    avg_val = sum(vals) / len(vals)
                    print(f"  - æ­£å¸¸å€¼å¹³å‡: {avg_val:.6f}")
                    
                    # å¦‚æœæœ‰infæˆ–æå¤§å€¼ï¼Œåªç”¨æ­£å¸¸å€¼è®¡ç®—å¹³å‡
                    if inf_count > 0 or large_count > 0:
                        print(f"  - å¿½ç•¥å¼‚å¸¸å€¼ï¼Œä½¿ç”¨æ­£å¸¸å€¼å¹³å‡")
                        avg_mse[method] = avg_val
                    else:
                        # è®¡ç®—æ€»å¹³å‡ï¼ˆåŒ…æ‹¬å¯èƒ½çš„æå€¼ï¼‰
                        all_finite_vals = vals.copy()
                        total_avg = sum(all_finite_vals) / len(all_finite_vals) if all_finite_vals else float('inf')
                        avg_mse[method] = total_avg
                else:
                    avg_mse[method] = float('inf')
            else:
                # å…¶ä»–æ–¹æ³•çš„æ­£å¸¸å¤„ç†
                if len(vals) > 0:
                    avg_mse[method] = sum(vals) / len(vals)
                else:
                    avg_mse[method] = float('inf')
            
            print(f"æ–¹æ³• {method}: {len(vals)} ä¸ªæœ‰æ•ˆå€¼ï¼Œå¹³å‡ MSE = {avg_mse[method]}")
        
        # è¾“å‡ºç»“æœ
        print("\nå„æ–¹æ³•å¹³å‡ MSE:")
        print("-" * 40)
        for method, v in sorted(avg_mse.items()):
            if not np.isnan(v):
                print(f"{method:20s}: {v:.6f}")
            else:
                print(f"{method:20s}: æ— æœ‰æ•ˆç»“æœ")
        
        # ä¿å­˜ç»“æœ
        results_df = pd.DataFrame([
            {'Method': method, 'Average_MSE': v} 
            for method, v in sorted(avg_mse.items())
        ])
        results_df.to_csv('mse_evaluation_results.csv', index=False)
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: mse_evaluation_results.csv")
        
        return avg_mse